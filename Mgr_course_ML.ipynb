{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShuYuHuang/mngr_ipynb/blob/main/Mgr_course_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ziwp9-hwfGrb"
      },
      "source": [
        "# **Machine Learning 案例手把手:$Tennessee\\;Eastman\\;Process\\;Simulation\\;Dataset$**\n",
        "透過實作田納西-伊士曼製程（Tennessee Eastman Process, TEP）資料集，我們會帶大家了解一個機器學習專案是如何從零開始實作的，培養定義問題和解決問題的能力。在這個案例中，我們會學到：\n",
        "\n",
        "1. 資料觀察、分析與視覺化\n",
        "2. 如何建立機器學習模型\n",
        "3. 如何評量模型成效與結果視覺化 \n",
        "4. 如何改善模型成效"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXU8qbKXKATQ"
      },
      "source": [
        "<a name=\"00\"></a>\n",
        "# 內容大綱\n",
        "\n",
        ">#### **1.   [資料科學流程（Data Science Process）](#01)**\n",
        ">#### **2.   [定義問題並了解資料來源](#02)**\n",
        ">#### **3.   [撰寫程式前置作業](#03)**\n",
        ">#### **4.   [資料讀取](#04)**\n",
        ">#### **5.   [資料的初步觀察和前處理](#05)**\n",
        ">#### **6.   [將資料建構成可以給模型的資料格式](#06)**\n",
        ">#### **7.   [資料切分為訓練集和驗證集](#07)**\n",
        ">#### **8.   [訓練模型：從簡單的模型開始](#08)**\n",
        ">#### **9.   [評估剛剛建立好的模型](#09)**\n",
        ">#### **10.   [如何改進結果](#10)**\n",
        "* 資料前處理－Feature scaling\n",
        "* 模型訓練：選用 Tree-based 模型\n",
        "* 模型訓練：選用 Ensemble 模型\n",
        "* 資料特徵工程－Principle Component Analysis（PCA）\n",
        "\n",
        ">#### **11.   [異常檢測的特殊作法](#11)**\n",
        "* PCA 故障檢測\n",
        "* Ensembling\n",
        "\n",
        ">#### **12.   [總結](#12)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpj32Ox8g2tg"
      },
      "source": [
        "<a name=\"01\"></a>\n",
        "# 1.資料科學流程（Data Science Process）\n",
        "\n",
        "[（返回內容大綱...）](#00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcpybYAzhYRs"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1JDljh89SHae6Me-ovZyafUSEObHL83p4\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3x1sCOdWuPh"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1TAkH6wu2B8xZ_l4vj9OLZXZXdDEXcbFS\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GTU_JkT6Rg2"
      },
      "source": [
        "<a name=\"02\"></a>\n",
        "# 2.定義問題並了解資料來源\n",
        "\n",
        "[（返回內容大綱...）](#00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyFBKShG7zyG"
      },
      "source": [
        "- ### Tennessee Eastman Process Simulation Dataset\n",
        "\n",
        "    *   原始論文：Downs, James J., and Ernest F. Vogel. \"A plant-wide industrial process control problem.\" Computers & chemical engineering 17.3 (1993): 245-255.\n",
        "    *   模擬資料集來源：https://www.kaggle.com/averkij/tennessee-eastman-process-simulation-dataset/activity\n",
        "    *   田納西-伊士曼製程（Tennessee Eastman Process, TEP）是由美國 Eastman 化學公司所建立的化工模型仿真平台所模擬的製程數據，為研究該類過程的故障診斷技術提供了一個實驗平台。其產生的資料具有時間遞移性、強耦合以及非線性特徵，因此難以得到精確的數學模型，使得模型驅動方法的性能不盡理想。數據驅動法中比較有代表性的如多變量統計，例如：主成分分析、因子分析、典型相關、聚類分析…等。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn3UzZqwd80k"
      },
      "source": [
        "- ### The diagram of process\n",
        "首先看一下系統中製程的輸入輸出是什麼: 整個化學反應製成主要有五個階段：反應器、冷凝器、循環壓縮機、分離器、汽提塔。主要反映過程如下：\n",
        "\n",
        "   - A（g）+ C（g）+ D（g）→ G（liq）　　產物 1\n",
        "   - A（g）+ C（g）+ E（g）→ H（liq）　　產物 2\n",
        "   - A（g）+ E（g）→ F（liq）　　　　　　副產物\n",
        "   - 3D（g）→ 2F（liq）　　　　　　　　　副產物\n",
        "\n",
        "* g: gas, 氣體\n",
        "* liq: liquid, 液體\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1MZIlW3CcUnyp4UX2zXryyU340lG5s5br\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouaeJjJC6met"
      },
      "source": [
        "##  Problem Define\n",
        "\n",
        "了解系統長什麼樣子後，要把想要的功能轉換成一個機器學習問題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy6idUZYIfzi"
      },
      "source": [
        "#### Machine Learning task\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1yxqyk2hd4y73pRosECxG2a3oXRm6gPHM\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ### 利用模擬資料來預測出現哪一種操作錯誤（分類問題，OK/ Faults 1/ Fault 2/ ...）"
      ],
      "metadata": {
        "id": "DZw3DM_YaSOV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjU3jfRx9u1-"
      },
      "source": [
        "- ### Process Faults  \n",
        "\n",
        "\n",
        "Variable number           | Process variable  | Type\n",
        ":--------------:|:-----:|:-----:\n",
        "IDV（1）    | A/C feed ratio, B composition constant（stream 4） |  Step \n",
        "IDV（2）    | B composition, A/C ratio constant（stream 4） |  Step \n",
        "IDV（3）    | D feed temperature（stream 2） |  Step \n",
        "IDV（4）    | Reactor cooling water inlet temperature |  Step \n",
        "IDV（5）    | Condenser cooling water inlet temperature |  Step \n",
        "IDV（6）    | A feed loss（stream 1） |  Step \n",
        "IDV（7）    | C header pressure loss-reduced availability（stream 4） |  Step \n",
        "IDV（8）    | A, B, C feed composition（stream 4） |  Random variation \n",
        "IDV（9）    | D feed temperature（stream 2） |  Random variation \n",
        "IDV（10）    | C feed temperature（stream 4） |  Random variation \n",
        "IDV（11）    | Reactor cooling water inlet temperature |  Random variation \n",
        "IDV（12）    | Condenser cooling water inlet temperature |  Random variation\n",
        "IDV（13）    | Reaction kinetics |  Slow drift\n",
        "IDV（14）    | Reactor cooling water valve |  Sticking  \n",
        "IDV（15）    | Condensor cooling water valve |  Sticking \n",
        "IDV（16）    | Unknown |  Unknown \n",
        "IDV（17）    | Unknown |  Unknown \n",
        "IDV（18）    | Unknown |  Unknown \n",
        "IDV（19）    | Unknown |  Unknown \n",
        "IDV（20）    | Unknown |  Unknown\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRMYhG-SPiY1"
      },
      "source": [
        "<a name=\"03\"></a>\n",
        "# 3.撰寫程式前置作業\n",
        "\n",
        "[（返回內容大綱...）](#00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRNRdUDPQv_R"
      },
      "source": [
        "## 載入所需模組與套件"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D15JLJ5gjmtb"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "【程式用法】－ import package\n",
        "\n",
        "- import package → 匯入 package 套件\n",
        "- import package as p → 匯入 package 並重新命名為 p\n",
        "- import package.module1 as m1 → 將 package 底下的 module1 匯入，並重新命名為 m1\n",
        "- from package import modeule1 → 從 package 將 module1 匯入（module1 存在於 package 底下）\n",
        "\n",
        "package在當前資料夾中的情況\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1rpK0Vbu9eTJTc3Rq70OP97zf0zdSHCM4\" width=\"300\">\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "查看已安裝的package"
      ],
      "metadata": {
        "id": "Io-ehBp8frYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip list"
      ],
      "metadata": {
        "id": "BK2aWyTtfgSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCRM8_nrC3Oa"
      },
      "source": [
        "import numpy as np                # 矩陣操作\n",
        "import pandas as pd                # 處理表格類型資料\n",
        "import matplotlib.pyplot as plt          # 視覺化\n",
        "import seaborn as sns               # 進階視覺化\n",
        "\n",
        "np.set_printoptions(edgeitems=25, linewidth=150, formatter=dict(float=lambda x: \"%.3g\" % x))  # 設定顯示範圍"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hk4F2I8Qnfa"
      },
      "source": [
        "## 下載資料至 Colab 空間"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BahwX_MZZV_v"
      },
      "source": [
        "# TEP_FaultFree_training_100run.csv\n",
        "!gdown --id 1ckTubYilJSW9q9cmp89NGpaarqQlt2NF\n",
        "\n",
        "# TEP_Fault_training_25run.csv\n",
        "!gdown --id 1ktdevLBIeFUSRwparVpyAEE7cTlKZxDg\n",
        "\n",
        "# TEP_Fault_training_10run.csv\n",
        "!gdown --id 1zwiqv6GsnCn3jbrHXZjRJhd9iW16Eeig\n",
        "\n",
        "# TEP_Fault_testing_10run.csv\n",
        "!gdown --id 1URWWeZQyO3FhS0U_nPuzMkqEb0EfX03Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UagvRmoxbGaq"
      },
      "source": [
        "<a name=\"03\"></a>\n",
        "# 4.資料讀取\n",
        "\n",
        "[（返回內容大綱...）](#00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGoJQFAzcoHE"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1yENx6FMBabxbiP0sw0cRrwdcxr5-HALm\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_AtFF88g6ds"
      },
      "source": [
        "\n",
        "資料集為模擬運行，採樣時間均為每 3 分鐘一筆，故每小時將有 20 筆監測資料。訓練集每回運行時間為 25 小時；測試集則為 48 小時。其中蒐集異常資料時，訓練集會以正常操作開始值至第 1 小時模擬錯誤操作，因此前 20 筆為正常資料，而後 480 筆為異常資料；測試集會以正常操作開始值至第 8 小時模擬錯誤操作，因此前 160 筆為正常資料，而後 800 筆為異常資料\n",
        "\n",
        "\n",
        "*   正常資料－ train: 500 筆，test: 960 筆\n",
        "*   異常資料－ train: 500 筆（前 20 筆為正常資料）， test: 960 筆（前 160 筆為正常資料）\n",
        "\n",
        "\n",
        "檔案說明:\n",
        "*   TEP_FaultFree_training_100run.csv: 模擬 100 回正常操作訓練資料集\n",
        "*   TEP_Fault_training_10run.csv: 模擬 10 回錯誤操作訓練資料集\n",
        "*   TEP_Fault_testing_10run.csv: 模擬 10 回錯誤操作測試資料集\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t3Il1KJOrbZ"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "【程式用法】－ arguments of function\n",
        "\n",
        "- function(X, a=1, b=None) → X 為必填的參數， a 預設值為 1, b 預設值為 None\n",
        "  - 若未填必填參數，則會報錯；若已有預設值之參數，未填則以預設值代入計算\n",
        "  - 順序可以調換，但需按照參數名稱給值。例如：function(X=array, a=2) 或 function(a=2, X=array)\n",
        "  - 若未給參數名稱，則以 function 原定參數順序給值。例如： function(array, 2) → X=array, a=2, b=None 代入計算\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s_qyOTESqY9"
      },
      "source": [
        "def function(X, a=1, b=None):\n",
        "  print(f'X={X}, a={a}, b={b}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d1G3uMwT-2f"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3yz2rNyD0AE"
      },
      "source": [
        "# 將指定名稱的 csv 檔案讀入變數為Pandas Dataframe\n",
        "train_normal_df = pd.read_csv('TEP_FaultFree_training_100run.csv')\n",
        "train_fault_df = pd.read_csv('TEP_Fault_training_10run.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A6XToeRRHFa"
      },
      "source": [
        "## 資料檢視"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li7njz9GZ-WU"
      },
      "source": [
        "train_normal_df.head(n=5)       # 資料前 n 筆"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2OoizIlRxHq"
      },
      "source": [
        "train_normal_df.info()       # 資料資訊：資料格式、筆數、欄位名稱及其形態等"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73pLj2EMjU7i"
      },
      "source": [
        "train_fault_df.head(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ujMZU-Feqi4"
      },
      "source": [
        "## 資料說明\n",
        "\n",
        "- faultNumber: 0 (正常樣本), 1~20（操作錯誤類型）\n",
        "- simulationRun: 第幾回合\n",
        "- sample: 回合中的第幾個樣本\n",
        "- xmeas_1~xmeas_41: 製程監控參數\n",
        "\n",
        "    - Continuous process measurements\n",
        "\n",
        "<table>\n",
        "    <thead>\n",
        "        <tr><th>Description</th><th>Variable number</th><th>Base case value</th><th>Units</th></tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "        <tr><th>A feed（stream 1）</th><th>xmeas_1</th><th>0.25052</th><th>kscmh</th></tr>\n",
        "        <tr><th>D feed（stream 2）</th><th>xmeas_2</th><th>3664.0</th><th>kgh&#8315;&sup1;</th></tr>\n",
        "        <tr><th>E feed（stream 3）</th><th>xmeas_3</th><th>4509.3</th><th>kgh&#8315;&sup1;</th></tr>\n",
        "        <tr><th>A and C feed（stream 4）</th><th>xmeas_4</th><th>9.3477</th><th>kscmh</th></tr>\n",
        "        <tr><th>Recycle flow（stream 8）</th><th>xmeas_5</th><th>26.902</th><th>kscmh</th></tr>\n",
        "        <tr><th>Reactor feed rate（stream 6）</th><th>xmeas_6</th><th>42.339</th><th>kscmh</th></tr>\n",
        "        <tr><th>Reactor pressure</th><th>xmeas_7</th><th>2705.0</th><th>kPa gauge</th></tr>\n",
        "        <tr><th>Reactor level</th><th>xmeas_8</th><th>75</th><th>%</th></tr>\n",
        "        <tr><th>Reactor temperature</th><th>xmeas_9</th><th>120.4</th><th>&deg;C</th></tr>\n",
        "        <tr><th>Purge rate（stream 9）</th><th>xmeas_10</th><th>0.33712</th><th>kscmh</th></tr>\n",
        "        <tr><th>Product separator temperature</th><th>xmeas_11</th><th>80.109</th><th>&deg;C</th></tr>\n",
        "        <tr><th>Product separator level</th><th>xmeas_12</th><th>50</th><th>%</th></tr>\n",
        "        <tr><th>Product separator pressure</th><th>xmeas_13</th><th>2633.7</th><th>kPa gauge</th></tr>\n",
        "        <tr><th>Product separator underflow（stream 10）</th><th>xmeas_14</th><th>25.16</th><th>m&sup3;h&#8315;&sup1;</th></tr>\n",
        "        <tr><th>Stripper level</th><th>xmeas_15</th><th>50</th><th>%</th></tr>\n",
        "        <tr><th>Stripper pressure</th><th>xmeas_16</th><th>3102.2</th><th>kPa gauge</th></tr>\n",
        "        <tr><th>Stripper underflow（stream 11）</th><th>xmeas_17</th><th>22.949</th><th>m&sup3;h&#8315;&sup1;</th></tr>\n",
        "        <tr><th>Stripper temperature</th><th>xmeas_18</th><th>65.731</th><th>&deg;C</th></tr>\n",
        "        <tr><th>Stripper steam flow</th><th>xmeas_19</th><th>230.31</th><th>kgh&#8315;&sup1;</th></tr>\n",
        "        <tr><th>Compressor work</th><th>xmeas_20</th><th>341.43</th><th>kW</th></tr>\n",
        "        <tr><th>Reactor cooling water outlet temperature</th><th>xmeas_21</th><th>94.599</th><th>&deg;C</th></tr>\n",
        "        <tr><th>Separator cooling water outlet temperature</th><th>xmeas_22</th><th>77.297</th><th>&deg;C</th></tr>\n",
        "    </tbody>\n",
        "</table>\n",
        "\n",
        "- \n",
        "    - Sampled process measurements\n",
        "\n",
        "<table>\n",
        "    <thead>\n",
        "        <tr><th>Reactor feed analysis（stream 6）</th></tr>\n",
        "    </thead>\n",
        "    <thead>\n",
        "        <tr><th>Component</th><th>Variable number</th><th>Base case value</th><th>Units</th><th>Sampling frequency=0.1h</th></tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "        <tr><th>A</th><th>xmeas_23</th><th>32.188</th><th>mol%</th></tr>\n",
        "        <tr><th>B</th><th>xmeas_24</th><th>8.8933</th><th>mol%</th></tr>\n",
        "        <tr><th>C</th><th>xmeas_25</th><th>26.383</th><th>mol%</th></tr>\n",
        "        <tr><th>D</th><th>xmeas_26</th><th>26.383</th><th>mol%</th></tr>\n",
        "        <tr><th>E</th><th>xmeas_27</th><th>26.383</th><th>mol%</th></tr>\n",
        "        <tr><th>F</th><th>xmeas_28</th><th>26.383</th><th>mol%</th></tr>\n",
        "    </tbody>\n",
        "    <thead>\n",
        "        <tr><th>Purge gas analysis（stream 9）</th></tr>\n",
        "    </thead>\n",
        "    <thead>\n",
        "        <tr><th>Component</th><th>Variable number</th><th>Base case value</th><th>Units</th><th>Sampling frequency=0.1h</th></tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "        <tr><th>A</th><th>xmeas_29</th><th>32.958</th><th>mol%</th></tr>\n",
        "        <tr><th>B</th><th>xmeas_30</th><th>13.823</th><th>mol%</th></tr>\n",
        "        <tr><th>C</th><th>xmeas_31</th><th>23.978</th><th>mol%</th></tr>\n",
        "        <tr><th>D</th><th>xmeas_32</th><th>1.2565</th><th>mol%</th></tr>\n",
        "        <tr><th>E</th><th>xmeas_33</th><th>18.579</th><th>mol%</th></tr>\n",
        "        <tr><th>F</th><th>xmeas_34</th><th>2.2633</th><th>mol%</th></tr>\n",
        "        <tr><th>G</th><th>xmeas_35</th><th>4.8436</th><th>mol%</th></tr>\n",
        "        <tr><th>H</th><th>xmeas_36</th><th>2.2986</th><th>mol%</th></tr>\n",
        "    </tbody>\n",
        "    <thead>\n",
        "        <tr><th>Product analysis（stream 11）</th></tr>\n",
        "    </thead>\n",
        "    <thead>\n",
        "        <tr><th>Component</th><th>Variable number</th><th>Base case value</th><th>Units</th><th>Sampling frequency=0.25h</th></tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "        <tr><th>D</th><th>xmeas_37</th><th>0.01787</th><th>mol%</th></tr>\n",
        "        <tr><th>E</th><th>xmeas_38</th><th>0.83570</th><th>mol%</th></tr>\n",
        "        <tr><th>F</th><th>xmeas_39</th><th>0.09858</th><th>mol%</th></tr>\n",
        "        <tr><th>G</th><th>xmeas_40</th><th>53.724</th><th>mol%</th></tr>\n",
        "        <tr><th>H</th><th>xmeas_41</th><th>43.828</th><th>mol%</th></tr>\n",
        "    </tbody>\n",
        "</table>\n",
        "\n",
        "- xmv_1~xmv_11: 製程操作參數\n",
        "\n",
        "<table>\n",
        "    <thead>\n",
        "        <tr><th>Description</th><th>Variable number</th><th>Base case value（%）</th><th>Low limit</th><th>High limit</th><th>Units</th></tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "        <tr><th>D feed flow（stream 2）</th><th>xmv_1</th><th>63.053</th><th>0</th><th>5811</th><th>kgh&#8315;&sup1;</th></tr>\n",
        "        <tr><th>E feed flow（stream 3）</th><th>xmv_2</th><th>53.980</th><th>0</th><th>8354</th><th>kgh&#8315;&sup1;</th></tr>\n",
        "        <tr><th>A feed flow（stream 1）</th><th>xmv_3</th><th>24.644</th><th>0</th><th>1.017</th><th>kscmh</th></tr>\n",
        "        <tr><th>A and C feed flow（stream 4）</th><th>xmv_4</th><th>61.302</th><th>0</th><th>15.25</th><th>kscmh</th></tr>\n",
        "        <tr><th>Compressor recycle valve</th><th>xmv_5</th><th>22.210</th><th>0</th><th>100</th><th>%</th></tr>\n",
        "        <tr><th>Purge valve（stream 9）</th><th>xmv_6</th><th>40.064</th><th>0</th><th>100</th><th>%</th></tr>\n",
        "        <tr><th>Separator pot liquid flow（stream 10）</th><th>xmv_7</th><th>38.100</th><th>0</th><th>65.71</th><th>m&sup3;h&#8315;&sup1;</th></tr>\n",
        "        <tr><th>Stripper liquid product flow（stream 11）</th><th>xmv_8</th><th>46.534</th><th>0</th><th>49.10</th><th>m&sup3;h&#8315;&sup1;</th></tr>\n",
        "        <tr><th>Stripper steam valve</th><th>xmv_9</th><th>47.446</th><th>0</th><th>100</th><th>%</th></tr>\n",
        "        <tr><th>Reactor cooling water flow</th><th>xmv_10</th><th>41.106</th><th>0</th><th>227.1</th><th>m&sup3;h&#8315;&sup1;</th></tr>\n",
        "        <tr><th>Condenser cooling water flow</th><th>xmv_11</th><th>18.114</th><th>0</th><th>272.6</th><th>m&sup3;h&#8315;&sup1;</th></tr>\n",
        "    </tbody>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAmDW4TXVwDc"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=12tjqIeKrDKmP8YBrdbW2fFTXPCanZYuO\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGNTuhH--8yB"
      },
      "source": [
        "對於此資料集 X 以及 y 分別是：\n",
        "- X: xmeas_1, xmeas_2, xmeas_3, ..., xmv_1, xmv_2, ...\n",
        "- y: faultNumber"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKJXbM-iR9zT"
      },
      "source": [
        "train_normal_df.describe()  # 資料描述：預設針對數值型態欄位統計相關數據，包含計數、平均值、標準差、最小、第一四分位距、第二四分位距、第三四分位距、最大值等。"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ADsubahjlQW"
      },
      "source": [
        "TEP_FaultFree_training_100run.csv 僅存在 faultNumber=0（Normal），而各個監測值的值域範圍差異極大。另外，不存在著欄位中僅有一種值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqUJOe-rjegy"
      },
      "source": [
        "train_fault_df.describe()  # 資料描述：預設針對數值型態欄位統計相關數據，包含計數、平均值、標準差、最小、第一四分位距、第二四分位距、第三四分位距、最大值等。"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyMbwlv1ksGA"
      },
      "source": [
        "TEP_Fault_training_10run.csv 中 faultNumber=1~20（Process Faults）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdXCNgZqxJbp"
      },
      "source": [
        "<a name=\"05\"></a>\n",
        "# 5.資料的初步觀察和前處理\n",
        "\n",
        "[（返回內容大綱...）](#00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOUQ_rfEex3k"
      },
      "source": [
        "#### 資料視覺化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU3OgUJ_e48e"
      },
      "source": [
        "取一小部分的資料來做比較：Normal data v.s. Fault data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXzuoda9MYyJ"
      },
      "source": [
        "【程式用法】- slicing\n",
        "\n",
        "- array[start:end:step] → 取用從 start（default=0）到 end（default=-1）的元素，間隔為 step（default=1）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzAKCtr5Mlvx"
      },
      "source": [
        "a = list(range(0, 15))\n",
        "print('a:\\t ', a)\n",
        "print('a[:]\\t ', a[:])\n",
        "print('a[:2]:\\t ', a[:2])\n",
        "print('a[2:6]:\\t ', a[2:6])\n",
        "print('a[1:]:\\t ', a[1:])\n",
        "print('a[2:8:2]:', a[2:8:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNnkaHYrJVq"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "【程式用法】－ pd.DataFrame\n",
        "\n",
        "- 取用其中指定名稱的欄位 → df[column_name] 或 df.column_name\n",
        "- 取用其中指定索引的筆數 → df.loc[row_name, :] 或 df.iloc[row_num, :]\n",
        "- df.loc[row_name, column_name]（loc: location, 填入名稱） v.s. df.iloc[row_num, column_num]（iloc: integer-location, 填入數字）\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhsWiZIqTUid"
      },
      "source": [
        "【程式用法】 - conditional statement\n",
        "\n",
        "輸出為 boolean （布林值）：True / False\n",
        "- a == b → a 是否等於 b\n",
        "- a != b → a 是否不等於 b\n",
        "- a in b → a 是否是 b 的元素\n",
        "- a and b → a 和 b 同時成立\n",
        "- a or b → a 或 b 成立\n",
        "- ...\n",
        "\n",
        "結合 array 索引 → 只取用為 True 的索引資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNoTJkRPVJkM"
      },
      "source": [
        "a = np.arange(10)\n",
        "print('a:\\t', a)\n",
        "print('a>5:\\t', a>5)\n",
        "print('a[a>5]:\\t', a[a>5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdbLVbVkVq9x"
      },
      "source": [
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZktWCsXlTYN"
      },
      "source": [
        "sample_train_normal = train_normal_df[train_normal_df.simulationRun==1]  # 透過條件限制 simulationRun=1 取用部分資料\n",
        "sample_train_fault = train_fault_df[train_fault_df.simulationRun==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dV9rf8elnZz"
      },
      "source": [
        "*   FaultNumber = 1 and 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4crXGwo0qvf4"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "【程式用法】－ for loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8yuEWXolR_0"
      },
      "source": [
        "for idx, i in enumerate(range(6, 12)):\n",
        "  print(f'{idx+1} th loop: {i}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEKYDi2-q7n0"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdLVSfsYuNhA"
      },
      "source": [
        "plt.figure(figsize=(15, 20))  # 設定畫布大小\n",
        "\n",
        "for idx, i in enumerate(range(0, 5)): # 查看第 i 個特徵的分布\n",
        "  plt.subplot(5, 1, idx+1)  # 在 5 列 1 行的畫布上，選擇編號為 idx+1 的位置\n",
        "  plt.yscale('log')  # 將 y 方向的間距取 log\n",
        "\n",
        "  plt.plot(sample_train_normal['sample'],\n",
        "           sample_train_normal.iloc[:, i+3],\n",
        "           label='Normal')  # 繪製折線圖\n",
        "\n",
        "  for j in range(2):  # 查看第 j 種 process fault\n",
        "    plt.plot(sample_train_fault.loc[sample_train_fault.faultNumber==j+1, 'sample'],\n",
        "             sample_train_fault.loc[sample_train_fault.faultNumber==j+1, f'xmeas_{i+1}'],\n",
        "             label=f'Fault_{j+1}')  # 繪製折線圖\n",
        "    \n",
        "  plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # 加上圖例\n",
        "  plt.axvline(x=20, color='r', linestyle='--')  # 畫垂直線\n",
        "  plt.title(sample_train_normal.columns[i+3])  # 設定標題\n",
        "  plt.tight_layout()  # 自動保持子圖之間的間距"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N8CAMmctBy-"
      },
      "source": [
        "plt.figure(figsize=(15, 20))  # 設定畫布大小\n",
        "\n",
        "for idx, i in enumerate(range(0, 5)):  # 查看第 i 個特徵的分布\n",
        "  plt.subplot(5, 1, idx+1)  # 在 5 列 1 行的畫布上，選擇編號為 idx+1 的位置\n",
        "  plt.yscale('log')  # 將 y 方向的間距取 log\n",
        "\n",
        "  plt.plot(sample_train_normal['sample'],\n",
        "           sample_train_normal.iloc[:, i+3],\n",
        "           label='Normal')  # 繪製折線圖\n",
        "\n",
        "  for j in range(2, 4):\n",
        "    plt.plot(sample_train_fault.loc[sample_train_fault.faultNumber==(j+1), 'sample'],\n",
        "             sample_train_fault.loc[sample_train_fault.faultNumber==(j+1), f'xmeas_{i+1}'],\n",
        "             label=f'Fault_{j+1}')  # 繪製折線圖\n",
        "  plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # 加上圖例\n",
        "  plt.axvline(x=20, color='r', linestyle='--')  # 畫垂直線\n",
        "  plt.title(sample_train_normal.columns[i+3])  # 設定標題\n",
        "  plt.tight_layout()  # 自動保持子圖之間的間距"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkIQrV1cuErr"
      },
      "source": [
        "先觀察少部分的資料：對於 faultNumber = 3 and 4 與 Normal 的前 5 個特徵分布十分相近，可以再進一步觀察其他特徵的分布差異並分析此分類是否存在問題。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Rwm4lGzdIE"
      },
      "source": [
        "comb_df = pd.concat((sample_train_normal.iloc[20:, :], sample_train_fault[sample_train_fault['sample']>=20]))  # 合併 normal 和 fault data\n",
        "comb_df['faultNumber'] = comb_df['faultNumber'].astype('int')  # 將欄位 faultNumber 轉換為 int（整數）型態"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhKCqmshvZZZ"
      },
      "source": [
        "*   盒型圖（Boxplot）"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=comb_df[['faultNumber', f'xmeas_1']])"
      ],
      "metadata": {
        "id": "Q0Oq87H8j3VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_H4rISC415X"
      },
      "source": [
        "plt.figure(figsize=(20, 12))  # 設定畫布大小\n",
        "\n",
        "for idx, i in enumerate(range(3)):  # 查看第 i 個特徵分布\n",
        "  plt.subplot(3, 1, idx+1)  # 在 3 列 1 行的畫布上，選擇編號為 idx+1 的位置\n",
        "  sns.boxplot(data=comb_df[['faultNumber', f'xmeas_{i+1}']],\n",
        "              x='faultNumber',\n",
        "              y=f'xmeas_{i+1}')  # 繪製盒鬚圖\n",
        "  plt.tight_layout()  # 自動保持子圖之間的間距"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnZNni7bvi6B"
      },
      "source": [
        "*   小提琴圖（Violinplot）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFCCr5WBnGLS"
      },
      "source": [
        "plt.figure(figsize=(25, 12))  # 設定畫布大小\n",
        "for idx, i in enumerate(range(3)):  # 查看第 i 個特徵分布\n",
        "  plt.subplot(3, 1, idx+1)  # 在 3 列 1 行的畫布上，選擇編號為 idx+1 的位置\n",
        "  sns.violinplot(data=comb_df[['faultNumber', f'xmeas_{i+1}']],\n",
        "                 x='faultNumber',\n",
        "                 y=f'xmeas_{i+1}')  # 繪製小提琴圖\n",
        "  plt.tight_layout()  # 自動保持子圖之間的間距"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHRI_vESvX06"
      },
      "source": [
        "*   相關係數熱圖"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmBaLdzsqAL8"
      },
      "source": [
        "corr = comb_df.iloc[:,[0]+[i for i in range(3, 55)]].corr(method='kendall')  # 計算 faultNumber 以及 xmeas, xmv 間的相關係數\n",
        "plt.figure(figsize=(30, 20))  # 設定畫布大小\n",
        "sns.heatmap(corr)  # 繪製熱圖（heatmap）"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEC88BF_fFED"
      },
      "source": [
        "comb_df['faultNumber'] = comb_df['faultNumber'].astype('str')  # 將欄位 faultNumber 轉換為 str（字串）型態\n",
        "new_comb_df = pd.get_dummies(comb_df, columns=['faultNumber'])  # 將 faultNumber 拆成 20 個欄位（One-hot encoding：屬於該類別，給值 1 反之為 0）"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P43r11zyfIZ0"
      },
      "source": [
        "new_comb_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrFwegR4gMzA"
      },
      "source": [
        "corr = new_comb_df.iloc[:,2:].corr(method='kendall')  # 計算各種 faultNumber 以及 xmeas, xmv 間的相關係數\n",
        "plt.figure(figsize=(30, 20))  # 繪製畫布大小\n",
        "sns.heatmap(corr)  # 繪製熱圖"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLGrqHq5IhWm"
      },
      "source": [
        "<a name=\"06\"></a>\n",
        "# 6.將資料建構成可以給模型的資料格式\n",
        "\n",
        "[（返回內容大綱...）](#00)\n",
        "\n",
        "*  所有的特徵都轉換為數字 → 模型才能做運算\n",
        "*  特徵不能包含目標欄位或從目標欄位做轉換而來 → 避免模型偷看答案\n",
        "*  考慮實際的流程，新一筆資料進來不具有目標值時，能蒐集到的特徵是否與訓練集一致 → 測試資料需要做的資料處理與訓練資料一致"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdP1eqAbFbjs"
      },
      "source": [
        "<a name=\"07\"></a>\n",
        "# 7.資料切分為訓練集和驗證集\n",
        "\n",
        "[（返回內容大綱...）](#00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8xajNvPGIkK"
      },
      "source": [
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1eHhK1FzQ2MjXXBZYWFrB6K7Opb4Om_aw\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIQX7ljekzev"
      },
      "source": [
        "train_all_10run = pd.concat((train_normal_df[train_normal_df['simulationRun']<=10], train_fault_df[train_fault_df['sample']>20]))  # 合併 normal 和 fault data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vugTrysTlJ8t"
      },
      "source": [
        "train_all_10run.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C21uxNsWA6vJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_all_10run.iloc[:, 3:].values,  # 按給定比例切分資料集\n",
        "                              train_all_10run['faultNumber'].values,\n",
        "                              test_size=0.25,  # 切分比例\n",
        "                              random_state=17)  # 隨機方式\n",
        "                              #, stratify=train_all_10run['faultNumber'].values)  # 按照 faultNumber 各類比例"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAkvMd8L_WqA"
      },
      "source": [
        "print(f'The shape of X_train: {X_train.shape}\\t y_train: {y_train.shape}')\n",
        "print(f'The shape of X_valid: {X_train.shape}\\t y_valid: {y_valid.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVL88cto-was"
      },
      "source": [
        "unique, counts = np.unique(train_all_10run['faultNumber'].values, return_counts=True)  # 計算各種 fault 有多少筆\n",
        "plt.bar(unique, counts)  # 繪製直條圖"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl586Jaq-4P2"
      },
      "source": [
        "unique, counts = np.unique(y_train, return_counts=True)  # 計算各種 fault 有多少筆\n",
        "plt.bar(unique, counts)  # 繪製直條圖"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se2-qS78Qq2j"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1xyVCmMwlMl0AKKOAlNo0Lraz_ZUmzui8\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWgZAfH9LEwa"
      },
      "source": [
        "<a name=\"08\"></a>\n",
        "# 8.訓練模型：從最簡單的分類模型開始\n",
        "\n",
        "[（返回內容大綱...）](#00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxWMYvgJwySq"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1WJOefdf2O8vfgyPy2V1Ka-jpjQomkYRF\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzvFEgaIZmDv"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1NmQHIl2opsoqjM3ETy3L0WS_5ETlZPLk\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKp24Cs2xDn6"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "【程式用法】－ Sklearn model\n",
        "- 建立模型 → model = MODEL()\n",
        "- 訓練模型 → model.fit(X, y)\n",
        "- 預測結果 → model.predict(X)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVHxdMh2-_tg"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUkkhgdL_N24"
      },
      "source": [
        "model = LogisticRegression()  # 建立模型\n",
        "model.fit(X_train, y_train)  # 訓練模型"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AcG-2JnLVti"
      },
      "source": [
        "<a name=\"09\"></a>\n",
        "# 9.評估剛剛建立好的模型\n",
        "\n",
        "[（返回內容大綱...）](#00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2I8x2QA0guk"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1TpFyCGBBp-DasT-TadxPaIuNveGn4NNr\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNBMPbwy0RVq"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1kwRkL7oE0xksDQHiEUATDMh35o8vo3tm\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzE33Hf_XRua"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beQzPHVXyees"
      },
      "source": [
        "- 訓練集上的結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bATPcSNfpm1O"
      },
      "source": [
        "# model.score(X_train, y_train)\n",
        "\n",
        "pred_train = model.predict(X_train)  # 預測結果\n",
        "print(classification_report(y_train, pred_train))  # 評估結果"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ns1AO56yjS5"
      },
      "source": [
        "- 驗證集上的結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP36CZ7fAbY9"
      },
      "source": [
        "# model.score(X_valid, y_valid)\n",
        "\n",
        "pred_valid = model.predict(X_valid)  # 預測結果\n",
        "print(classification_report(y_valid, pred_valid))  # 評估結果"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0avLJdCZQOzY"
      },
      "source": [
        "plt.figure(figsize=(15, 10))  # 繪製畫布大小\n",
        "sns.set(font_scale=1.4)  # 調整文字大小\n",
        "sns.heatmap(confusion_matrix(y_valid, pred_valid))  # 畫出混淆矩陣（Confusion matrix）"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifiMIOwrLyaW"
      },
      "source": [
        "<a name=\"10\"></a>\n",
        "# 10.如何改進結果\n",
        "\n",
        "[（返回內容大綱...）](#00)\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1lcnLXQjJysdYkZpMRuj4KA0ZhhLaViwz\" width=\"1000\">\n",
        "\n",
        "\n",
        "先看訓練集，再看驗證集！\n",
        "\n",
        "- 訓練集結果不好（Underfitting）\n",
        "   - 資料處理（feature scaling, feature selection, feature engineering）\n",
        "   - 增加模型複雜度（選擇其他模型，調整參數）\n",
        "- 訓練集結果好，驗證集結果不好（Overfitting）\n",
        "   * 增加資料量\n",
        "   * 減少雜訊資料\n",
        "   * 降低模型複雜度\n",
        "   * 增加隨機性\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9atv_SSxl8U"
      },
      "source": [
        "#### 資料前處理 － Feature scaling\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNpWnENpzP7O"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1fXTPWens9QeujBfOg78P6ljiwz6hHncd\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK02Qxyg7awR"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler  # (X-mean(X))/std(X)\n",
        "from sklearn.preprocessing import MinMaxScaler   # (X-min(X))/(max(X)-min(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX99X_t7v5tA"
      },
      "source": [
        "def data_preprocessing(df_input, train=True, sc=None):\n",
        "    if train:  # 若是 training data，則按照輸入資料做 feature scaling\n",
        "        sc = StandardScaler()\n",
        "#         sc = MinMaxScaler()\n",
        "        df = sc.fit_transform(df_input)\n",
        "\n",
        "    else:  # 若是 testing data，則按照 training scale 做 feature scaling\n",
        "        df = sc.transform(df_input)\n",
        "    return df, sc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJroi7gx9-tm"
      },
      "source": [
        "train_all_10run.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b927YGY7vsO"
      },
      "source": [
        "train_transform_data, sc = data_preprocessing(train_all_10run.iloc[:, 3:])  # feature scaling for 52 features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENYYG3k28pc0"
      },
      "source": [
        "pd.DataFrame(train_transform_data, columns=train_all_10run.columns[3:]).describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zdf_KW89RYc"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(train_transform_data,  # 按給定比例切分資料集\n",
        "                              train_all_10run['faultNumber'].values,\n",
        "                              test_size=0.25,  # 切分比例\n",
        "                              random_state=17,  # 隨機方式\n",
        "                              stratify=train_all_10run['faultNumber'].values)  # 按照 faultNumber 各類比例"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HnlO0ykN1hQ"
      },
      "source": [
        "model = LogisticRegression()  # 建立模型\n",
        "model.fit(X_train, y_train)  # 訓練模型"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuidkXOgCQou"
      },
      "source": [
        "- 訓練集上的結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ia7FCOHN1hS"
      },
      "source": [
        "# model.score(X_train, y_train)\n",
        "\n",
        "pred_train = model.predict(X_train)  # 預測結果\n",
        "print(classification_report(y_train, pred_train))  # 評估結果"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKRESOAxCWId"
      },
      "source": [
        "- 驗證集上的結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrGsnes4N1hS"
      },
      "source": [
        "pred_valid = model.predict(X_valid)  # 預測結果\n",
        "print(classification_report(y_valid, pred_valid))  # 評估結果"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38E_tdPEQLbw"
      },
      "source": [
        "plt.figure(figsize=(15, 10))  # 繪製畫布大小\n",
        "sns.set(font_scale=1.4)  # 調整文字大小\n",
        "sns.heatmap(confusion_matrix(y_valid, pred_valid))  # 畫出混淆矩陣（Confusion matrix）"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghhmfLQly0TM"
      },
      "source": [
        "#### 模型訓練：選用 Tree-based 模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbgQSHUzOW0t"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1eETo_soxgPEkh7TZAHXnQorswEqd4JN_\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjmYNrq7sa2Q"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0m9ZaXMC0aw"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(train_transform_data,  # 按給定比例切分資料集\n",
        "                              train_all_10run['faultNumber'].values,\n",
        "                              test_size=0.25,  # 切分比例\n",
        "                              random_state=17,  # 隨機方式\n",
        "                              stratify=train_all_10run['faultNumber'].values)  # 按照 faultNumber 各類比例"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NESY3Nv0C0ax"
      },
      "source": [
        "model = DecisionTreeClassifier()  # 建立模型\n",
        "model.fit(X_train, y_train)  # 訓練模型"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0keB_MsC0ay"
      },
      "source": [
        "- 訓練集上的結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD4FOKFpC0az"
      },
      "source": [
        "# model.score(X_train, y_train)\n",
        "\n",
        "pred_train = model.predict(X_train)  # 預測結果\n",
        "print(classification_report(y_train, pred_train))  # 評估結果"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srrXb6b_C0az"
      },
      "source": [
        "- 驗證集上的結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9y5tdQ5C0a0"
      },
      "source": [
        "pred_valid = model.predict(X_valid)  # 預測結果\n",
        "print(classification_report(y_valid, pred_valid))  # 評估結果"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI9v4swdC0a1"
      },
      "source": [
        "plt.figure(figsize=(15, 10))  # 繪製畫布大小\n",
        "sns.set(font_scale=1.4)  # 調整文字大小\n",
        "sns.heatmap(confusion_matrix(y_valid, pred_valid))  # 畫出混淆矩陣（Confusion matrix）"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1hx1k6NKBx8"
      },
      "source": [
        "### Overfitting\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1eJn1COvfonypuFbOG1KmMIfsmfLrW0qa\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJP1GqigKVtG"
      },
      "source": [
        "模型過度擬合在訓練資料集上（綠色線）達到很高的準確率，導致在未參與訓練的驗證資料集上表現不佳\n",
        "\n",
        "抑制 Overfitting 的方法：\n",
        "* 增加資料量\n",
        "* 減少雜訊資料\n",
        "* 降低模型複雜度\n",
        "* 增加隨機性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWKBYr7A1i1j"
      },
      "source": [
        "#### 模型訓練：選用 Ensemble 模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DWe4oXfPTLU"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1WaIuzeOZn6-wwzlkLoinSaCu4hGO3R5c\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5EUDEmQs930"
      },
      "source": [
        "from lightgbm import LGBMClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Q1v6tHDGD2"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(train_transform_data,  # 按給定比例切分資料集\n",
        "                              train_all_10run['faultNumber'].values,\n",
        "                              test_size=0.25,  # 切分比例\n",
        "                              random_state=17,  # 隨機方式\n",
        "                              stratify=train_all_10run['faultNumber'].values)  # 按照 faultNumber 各類比例"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOwdNZXzDGD3"
      },
      "source": [
        "model = LGBMClassifier()  # 建立模型\n",
        "model.fit(X_train, y_train)  # 訓練模型"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVNHHFuZDGD4"
      },
      "source": [
        "- 訓練集上的結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_WaQm63DGD4"
      },
      "source": [
        "# model.score(X_train, y_train)\n",
        "\n",
        "pred_train = model.predict(X_train)  # 預測結果\n",
        "print(classification_report(y_train, pred_train))  # 評估結果"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR0jbeqkDGD5"
      },
      "source": [
        "- 驗證集上的結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgiJ9DImDGD5"
      },
      "source": [
        "pred_valid = model.predict(X_valid)  # 預測結果\n",
        "print(classification_report(y_valid, pred_valid))  # 評估結果"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TymqHv3ADGD6"
      },
      "source": [
        "plt.figure(figsize=(15, 10))  # 繪製畫布大小\n",
        "sns.set(font_scale=1.4)  # 調整文字大小\n",
        "sns.heatmap(confusion_matrix(y_valid, pred_valid))  # 畫出混淆矩陣（Confusion matrix）"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "___hhiiFOHYm"
      },
      "source": [
        "#### 資料特徵工程 － Principle Component Analysis（PCA）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXy7NnfpNZdM"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1zv3t7dESXMvQ8PHVMHJj3Wtbbee8giXw\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gCM3_6pR3tx"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1Rl5572Lrr35mVO5TZF-qWzAyZLBllAOZ\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvFALri7O0Nj"
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X8AXJJWDjKj"
      },
      "source": [
        "pca = PCA(n_components=0.99) # n_components: int, float or ‘mle’\n",
        "pca.fit(train_transform_data)  # 計算共變異數矩陣並進行特徵分解\n",
        "pca_transformed_data = pca.transform(train_transform_data)  # pca 降維轉換"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMGdCnE8SkRV"
      },
      "source": [
        "pca_transformed_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef99PN8hSojD"
      },
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ-bkmDNTWD0"
      },
      "source": [
        "pca.explained_variance_ratio_.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAlPY7n4ELKD"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(pca_transformed_data,  # 按給定比例切分資料集\n",
        "                              train_all_10run['faultNumber'].values,\n",
        "                              test_size=0.25,  # 切分比例\n",
        "                              random_state=17,  # 隨機方式\n",
        "                              stratify=train_all_10run['faultNumber'].values)  # 按照 faultNumber 各類比例"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l8n4oRDELKE"
      },
      "source": [
        "model = LGBMClassifier()  # 建立模型\n",
        "model.fit(X_train, y_train)  # 訓練模型"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q4r4KH7ELKF"
      },
      "source": [
        "- 訓練集上的結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwLsNMp9ELKG"
      },
      "source": [
        "# model.score(X_train, y_train)\n",
        "\n",
        "pred_train = model.predict(X_train)  # 預測結果\n",
        "print(classification_report(y_train, pred_train))  # 評估結果"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmt4ThreELKG"
      },
      "source": [
        "- 驗證集上的結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlE6iHPdELKH"
      },
      "source": [
        "pred_valid = model.predict(X_valid)  # 預測結果\n",
        "print(classification_report(y_valid, pred_valid))  # 評估結果"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gspIIPXELKI"
      },
      "source": [
        "plt.figure(figsize=(15, 10))  # 繪製畫布大小\n",
        "sns.set(font_scale=1.4)  # 調整文字大小\n",
        "sns.heatmap(confusion_matrix(y_valid, pred_valid))  # 畫出混淆矩陣（Confusion matrix）"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia1wA9RO1IwD"
      },
      "source": [
        "<a name=\"11\"></a>\n",
        "# 11.異常檢測的特殊作法\n",
        "\n",
        "[（返回內容大綱...）](#00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXpUHzrwqBFA"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1thtcjrMyxUDW9c4cD4b9zlqtOHzWF-ku\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmOVgpzL2b3R"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1R4ejpC3stv9FWHyKz_SNYX5bI4iR-C9e\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-_cBo4-2ovZ"
      },
      "source": [
        "通常在做異常檢測時，蒐集到的資料集為大量的正常資料，以及少數的異常資料。因此，若以單純的分類做法，往往會因為資料不平均而導致未能檢測出異常資料。\n",
        "\n",
        "然而在異常檢測問題上，會利用以下的想法，來訓練模型：\n",
        "* 僅訓練正常資料（學習正常資料的特徵）\n",
        "* 利用正常資料的特徵轉換，對所有資料做轉換，將預期異常資料無法正常轉換或者與正常資料的特徵有較大的差異"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-A-f9mw4UKi"
      },
      "source": [
        "為了更貼近實際狀況－正常資料與異常資料比例差異懸殊，將會使用模擬 100 回正常訓練資料，以及 10 回異常資料來做演示"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeAn59FV4YYh"
      },
      "source": [
        "#### PCA 故障檢測"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUuIFHVM5BPs"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1g4SIjsGk_DjbiriOkdQbH2pKFl_ItZXD\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_fx9j2syPL2"
      },
      "source": [
        "* T$^2$ 統計量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KitKvECi4Qvb"
      },
      "source": [
        "train_normal_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyHbhqfqIlVe"
      },
      "source": [
        "sc = StandardScaler()\n",
        "sc_normal = sc.fit_transform(train_normal_df.iloc[:, 3:])  # 按照 normal data scale 做 feature scaling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxs-c9_iFq9d"
      },
      "source": [
        "pca_normal = PCA(n_components=0.99) # n_components: int, float or ‘mle’\n",
        "transformed_normal_data = pca_normal.fit_transform(sc_normal)  # 計算共變異數矩陣並進行特徵分解後，做降維轉換"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5Z8tfiaEvaE"
      },
      "source": [
        "pca_normal.explained_variance_ratio_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH-dw-VXEqYE"
      },
      "source": [
        "transformed_normal_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mRLCeRFSzzt"
      },
      "source": [
        "T2_normal_data = (transformed_normal_data**2 / pca_normal.explained_variance_).sum(axis=1)  # 計算 T^2 統計量"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPjM3culJBnA"
      },
      "source": [
        "sc_fault = sc.transform(train_fault_df.iloc[:, 3:])  # 按照 normal data scale 對 fault data 做 feature scaling\n",
        "transformed_fault_data = pca_normal.transform(sc_fault)  # 按照 normal data 的降維方式對 fault data 做降維"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVGIsb4XFrDx"
      },
      "source": [
        "transformed_fault_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewuc9ARZFaX6"
      },
      "source": [
        "T2_fault_data = (transformed_fault_data**2 / pca_normal.explained_variance_).sum(axis=1)  # 計算 T^2 統計量"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jmMyhBeF0xL"
      },
      "source": [
        "plt.figure(figsize=(25, 40))  # 設定畫布大小\n",
        "for idx, i in enumerate(range(20)):  # 查看第 i 種 fault 的 T^2 分布\n",
        "  plt.subplot(10, 2, idx+1)  # 在 10 列 2 行的畫布上，選擇編號為 idx+1 的位置\n",
        "  plt.yscale('log')  # 將 y 方向的間距取 log\n",
        "  \n",
        "  plt.plot(range(len(T2_normal_data[:500])),  # 繪製折線圖\n",
        "           T2_normal_data[:500],\n",
        "           label='Normal')\n",
        "  \n",
        "  plt.plot(range(len(T2_fault_data[i*500:(i+1)*500])),  # 繪製折線圖\n",
        "           T2_fault_data[i*500:(i+1)*500],\n",
        "           label=f'Fault_{i+1}')\n",
        "  \n",
        "  plt.axvline(x=20, color='r', linestyle='--')  # 畫垂直線\n",
        "  plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # 加上圖例\n",
        "  plt.tight_layout()  # 自動保持子圖之間的間距"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRdO-uQRyXqr"
      },
      "source": [
        "* Q 統計量，又名 SPE（Square Prediction Error） 統計量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFWVNyRQPZvm"
      },
      "source": [
        "normal_project = np.einsum('ik,kf->ifk',\n",
        "               transformed_normal_data,\n",
        "               pca_normal.components_).sum(axis=2)  # 計算 normal data 的投影向量\n",
        "Q_normal_data = ((normal_project-(train_normal_df.iloc[:, 3:]-train_normal_df.mean()[3:]))**2).sum(axis=1) # 計算 Q 統計量"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq-J_JiLVeTg"
      },
      "source": [
        "fault_project = np.einsum('ik,kf->ifk',\n",
        "               transformed_fault_data,\n",
        "               pca_normal.components_).sum(axis=2)  # 計算 fault data 的投影向量\n",
        "Q_fault_data = ((fault_project-(train_fault_df.iloc[:, 3:]-train_fault_df.mean()[3:]))**2).sum(axis=1)  # 計算 Q 統計量"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdowILm5W9HF"
      },
      "source": [
        "plt.figure(figsize=(25, 40))  # 設定畫布大小\n",
        "for idx, i in enumerate(range(20)):  # 查看第 i 種 fault 的 Q 分布\n",
        "  plt.subplot(10, 2, idx+1)  # 在 10 列 2 行的畫布上，選擇編號為 idx+1 的位置\n",
        "  plt.yscale('log')  # 將 y 方向的間距取 log\n",
        "\n",
        "  plt.plot(range(len(Q_normal_data[:500])),  # 繪製折線圖\n",
        "           Q_normal_data[:500],\n",
        "           label='Normal')\n",
        "  \n",
        "  plt.plot(range(len(Q_fault_data[i*500:(i+1)*500])),  # 繪製折線圖\n",
        "           Q_fault_data[i*500:(i+1)*500],\n",
        "           label=f'Fault_{i+1}')\n",
        "  \n",
        "  plt.axvline(x=20, color='r', linestyle='--')  # 畫垂直線\n",
        "  plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # 加上圖例\n",
        "  plt.tight_layout()  # 自動保持子圖之間的間距"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJf_V_wk1qCz"
      },
      "source": [
        "#### Ensembling\n",
        "\n",
        "*   訓練 N 個模型，利用正常訓練集中的 N-1 個特徵，去預測餘下的 1 個特徵值\n",
        "*   預測異常訓練集的各個特徵\n",
        "*   計算預測出來的所有特徵值，與原始值的差異（使用 MSE 等指標評估距離）\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1wyljNyqMk9LiXhs7XmAzmc_l0TV_cHjc\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_gGa4jLOL1X"
      },
      "source": [
        "sc = StandardScaler()\n",
        "sc_normal_df = pd.DataFrame(sc.fit_transform(train_normal_df.iloc[:, 3:]),  # 按照 normal data scale 做 feature scaling\n",
        "                columns=train_normal_df.iloc[:, 3:].columns) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKa32UTYW4bs"
      },
      "source": [
        "import tqdm\n",
        "from lightgbm import LGBMRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IegcQX7NpBtb"
      },
      "source": [
        "def train(df, cols_to_predict):\n",
        "  models = {}  # 各個模型存放位置\n",
        "  pbar = tqdm.tqdm_notebook(cols_to_predict)\n",
        "  for col in pbar:\n",
        "    pbar.set_description(f'Training model for {col}')\n",
        "    model = LGBMRegressor(learning_rate=0.1)  # 建立模型\n",
        "    tr_x = df.drop([col],axis=1)  # 取其中 N-1 個特徵作為 X\n",
        "    target = df[col]  # 取剩餘的 1 個特徵作為 y\n",
        "    \n",
        "    model.fit(X=tr_x, y=target) # 訓練模型\n",
        "    models[col] = model  # 將訓練好的模型存放至 models\n",
        "    \n",
        "  return models\n",
        "\n",
        "def predict(models, df, cols_to_predict):\n",
        "  preds = []\n",
        "  for col in cols_to_predict:\n",
        "      test_x = df.drop([col], axis=1)  # 取其中 N-1 個特徵作為 X\n",
        "      \n",
        "      pred = models[col].predict(test_x)  # 預測剩餘的 1 個特徵\n",
        "      preds.append(pred)\n",
        "  \n",
        "  return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcTPYgFLphZG"
      },
      "source": [
        "sc_normal_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M65j3DwIpZER"
      },
      "source": [
        "features_to_predict = sc_normal_df.columns\n",
        "models = train(sc_normal_df, features_to_predict)  # 透過自定義的 train 訓練模型"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na6ut5ChqDeE"
      },
      "source": [
        "def get_mse(sample, preds):\n",
        "    return np.square((sample.loc[:,features_to_predict] - np.transpose(preds))**2).mean(axis=1)  # 計算 mean square error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohcaPqDSqM8n"
      },
      "source": [
        "plt.figure(figsize=(25,40))  # 設定畫布大小\n",
        "plt.title('MSE for a normal and fault samples')  # 設定標題\n",
        "\n",
        "normal_Run = np.random.randint(100)+1  # 隨機取正常資料的其中一回合\n",
        "print(f'Normal simulationRun = {normal_Run}')\n",
        "normal_sample = pd.DataFrame(sc.transform(train_normal_df[train_normal_df.simulationRun==normal_Run].iloc[:, 3:]),\n",
        "                columns=train_normal_df.columns[3:])\n",
        "normal_preds = predict(models, normal_sample, features_to_predict)  # 透過自定義的 predict 預測結果\n",
        "\n",
        "fault_Run = np.random.randint(10)+1  # 隨機取異常資料的其中一回合\n",
        "print(f'fault simulationRun = {fault_Run}')\n",
        "for idx, i in enumerate(range(20)):\n",
        "  plt.subplot(10, 2, idx+1)  # 在 10 列 2 行的畫布上，選擇編號為 idx+1 的位置\n",
        "  plt.yscale('log')  # 將 y 方向的間距取 log\n",
        "  plt.plot(get_mse(normal_sample, normal_preds),\n",
        "        label='Normal')  # 得到預測結果與原始特徵之間的 MSE 值\n",
        "  faulty_sample = pd.DataFrame(sc.transform(train_fault_df[(train_fault_df.simulationRun==fault_Run) & (train_fault_df.faultNumber==(i+1))].iloc[:,3:]),\n",
        "                  columns=train_fault_df.columns[3:])\n",
        "  faulty_preds = predict(models, faulty_sample, features_to_predict)  # 透過自定義的 predict 預測結果\n",
        "  plt.plot(get_mse(faulty_sample, faulty_preds),\n",
        "        label=f'Fault_{i+1}')  # 得到預測結果與原始特徵之間的 MSE 值\n",
        "  plt.axvline(x=20, color='r', linestyle='--')  # 畫垂直線\n",
        "  plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # 加上圖例\n",
        "  plt.tight_layout()  # 自動保持子圖之間的間距"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH318romLIMv"
      },
      "source": [
        "* 不同 SimulationRun 的結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k41HFB6nxy73"
      },
      "source": [
        "plt.figure(figsize=(25,40))  # 設定畫布大小\n",
        "plt.title('MSE for a normal and fault samples')  # 設定標題\n",
        "\n",
        "normal_Run = np.random.randint(100)+1  # 隨機取正常資料的其中一回合\n",
        "print(f'Normal simulationRun = {normal_Run}')\n",
        "normal_sample = pd.DataFrame(sc.transform(train_normal_df[train_normal_df.simulationRun==normal_Run].iloc[:, 3:]),\n",
        "                columns=train_normal_df.columns[3:])\n",
        "normal_preds = predict(models, normal_sample, features_to_predict)  # 透過自定義的 predict 預測結果\n",
        "\n",
        "fault_Run = np.random.randint(10)+1  # 隨機取異常資料的其中一回合\n",
        "print(f'fault simulationRun = {fault_Run}')\n",
        "for idx, i in enumerate(range(20)):\n",
        "  plt.subplot(10, 2, idx+1)  # 在 10 列 2 行的畫布上，選擇編號為 idx+1 的位置\n",
        "  plt.yscale('log')  # 將 y 方向的間距取 log\n",
        "  plt.plot(get_mse(normal_sample, normal_preds),\n",
        "        label='Normal')  # 得到預測結果與原始特徵之間的 MSE 值\n",
        "  faulty_sample = pd.DataFrame(sc.transform(train_fault_df[(train_fault_df.simulationRun==fault_Run) & (train_fault_df.faultNumber==(i+1))].iloc[:,3:]),\n",
        "                  columns=train_fault_df.columns[3:])\n",
        "  faulty_preds = predict(models, faulty_sample, features_to_predict)  # 透過自定義的 predict 預測結果\n",
        "  plt.plot(get_mse(faulty_sample, faulty_preds),\n",
        "        label=f'Fault_{i+1}')  # 得到預測結果與原始特徵之間的 MSE 值\n",
        "  plt.axvline(x=20, color='r', linestyle='--')  # 畫垂直線\n",
        "  plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # 加上圖例\n",
        "  plt.tight_layout()  # 自動保持子圖之間的間距"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RSnJaOw6L3K"
      },
      "source": [
        "* 大多數的 Fault 都與 Normal 的 MSE 值有明顯的差距，如何去界定之間的 threshold，可以藉由多次的實驗訂定，或者設定分布的信心水準找到對應的統計量作為分界點。\n",
        "* 在 Fault_3, Fault_9, Fault_15 幾乎分布與 Normal 無差別，也有資料顯出此三種異常出現蒐集對應有誤的情況。\n",
        "* 此資料集也關乎時間上的關聯性，由 Fault 17 所呈現的圖形明顯看出具有週期性的變化，因此在機器學習的做法當中，可以加入往前推算一段時間的所有特徵，或者時間相關的因素在特徵當中，例如：過往時間段的平均值、最大值、最小值等等。\n",
        "\n",
        "* 然而在深度學習的做法當中，有專門為時間序列所設計的 RNN 模型，也是未來可以模型方面嘗試的方向。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQpDINohqaG4"
      },
      "source": [
        "<a name=\"12\"></a>\n",
        "# 12.總結\n",
        "\n",
        "[（返回內容大綱...）](#00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6aXAj8Z5fcG"
      },
      "source": [
        "## 資料\n",
        "* 資料處理和模型訓練是反覆檢驗的\n",
        "* 資料處理應盡可能的與背景知識相呼應\n",
        "* 好的且乾淨的資料可以解決大多數的問題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euWOKT4W7McE"
      },
      "source": [
        "## 模型\n",
        "* 設計特殊模型時要考慮資料輸入資料格式的類型，以及輸出與標籤相應的目標\n",
        "* 模型的設計也關乎所擁有的運算資源，追求精準度或者速度\n",
        "* 不管是機器學習或深度學習，單純參數的調整可以提升的預測效能有限"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33U0FzZi7Zjb"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "***簡而言之，決定模型性能的常常是資料的好壞。而資料的好壞又會被資料處理的方式影響。能否找到好的資料處理方式既切合商業目標，並讓模型好學習是資料科學專案的重點。***"
      ]
    }
  ]
}